import os
import requests
from PIL import Image
from io import BytesIO

# Replace with your actual keys
FLICKR_PUBLIC = '9ea8e2d5e1467623cb4fbc3c72393a84'
FLICKR_SECRET = '63d5821a232e80d4'
UNSPLASH_ACCESS_KEY = 'LYmX41jbGfSMPM4AqXdicXNOjW7_VVQs7IVveXuL2jk'
PIXABAY_API_KEY = '46309966-0cd412cf3e091d84795111fad'

# Correct folder path for Windows (use raw string or double backslashes)
folder_path = r'C:\Users\arian\Downloads\image_folder'
os.makedirs(folder_path, exist_ok=True)

# Function to download and save an image
def download_and_save_image(image_url, image_name):
    try:
        response = requests.get(image_url)
        image = Image.open(BytesIO(response.content))
        image_path = os.path.join(folder_path, f"{image_name}.jpg")
        image.save(image_path)
        print(f"Saved: {image_name}")
    except Exception as e:
        print(f"Failed to save {image_name}: {e}")

# Fetch images from Flickr
def fetch_flickr_images(tags, per_page=100, total_images=450):
    total_fetched = 0
    page = 1
    while total_fetched < total_images:
        flickr_search_params = {
            'api_key': FLICKR_PUBLIC,
            'method': 'flickr.photos.search',
            'format': 'json',
            'nojsoncallback': 1,
            'tags': tags,
            'per_page': per_page,
            'page': page
        }
        response = requests.get('https://api.flickr.com/services/rest/', params=flickr_search_params)
        data = response.json()

        if 'photos' in data and 'photo' in data['photos']:
            photos = data['photos']['photo']
            if not photos:
                print(f"No more photos available on Flickr for page {page}.")
                break

            for photo in photos:
                photo_url = f"https://live.staticflickr.com/{photo['server']}/{photo['id']}_{photo['secret']}.jpg"
                image_name = f"flickr_{photo['id']}"
                download_and_save_image(photo_url, image_name)
                total_fetched += 1
                if total_fetched >= total_images:
                    break
        else:
            print("No more results or API limit reached.")
            break
        page += 1

    print(f"Total Flickr images downloaded: {total_fetched}")

# Fetch images from Unsplash
def fetch_unsplash_images(query, per_page=30, total_images=450):
    unsplash_url = "https://api.unsplash.com/search/photos"
    headers = {'Authorization': f'Client-ID {UNSPLASH_ACCESS_KEY}'}
    total_fetched = 0
    page = 1

    while total_fetched < total_images:
        params = {'query': query, 'per_page': per_page, 'page': page}
        response = requests.get(unsplash_url, headers=headers, params=params)
        
        if response.status_code == 200:
            data = response.json()
            if 'results' in data:
                for photo in data['results']:
                    photo_url = photo['urls']['regular']
                    image_name = f"unsplash_{photo['id']}"
                    download_and_save_image(photo_url, image_name)
                    total_fetched += 1
                    if total_fetched >= total_images:
                        break
            else:
                print("No results found from Unsplash.")
                break
        else:
            print(f"Failed to fetch Unsplash images. Status code: {response.status_code}")
            print(f"Response text: {response.text}")
            break
        page += 1

    print(f"Total Unsplash images downloaded: {total_fetched}")

# Fetch images from Pixabay
def fetch_pixabay_images(query, per_page=200, total_images=450):
    pixabay_url = 'https://pixabay.com/api/'
    params = {
        'key': PIXABAY_API_KEY,
        'q': query,
        'per_page': per_page,
    }
    total_fetched = 0
    page = 1

    while total_fetched < total_images:
        params['page'] = page
        response = requests.get(pixabay_url, params=params)

        if response.status_code == 200:
            data = response.json()
            if 'hits' in data:
                for photo in data['hits']:
                    photo_url = photo['largeImageURL']
                    image_name = f"pixabay_{photo['id']}"
                    download_and_save_image(photo_url, image_name)
                    total_fetched += 1
                    if total_fetched >= total_images:
                        break
            else:
                print("No results found from Pixabay.")
                break
        else:
            print(f"Failed to fetch Pixabay images. Status code: {response.status_code}")
            print(f"Response text: {response.text}")
            break
        page += 1

    print(f"Total Pixabay images downloaded: {total_fetched}")

# Run the functions for the APIs
if __name__ == '__main__':
    # Fetch 450 images from Flickr with fallback message
    print("Fetching images from Flickr...")
    fetch_flickr_images(tags='brick texture, brick wall', per_page=100, total_images=450)

    # Fetch 450 images from Unsplash
    print("Fetching images from Unsplash...")
    fetch_unsplash_images(query='brick texture', per_page=30, total_images=450)

    # Fetch 450 images from Pixabay
    print("Fetching images from Pixabay...")
    fetch_pixabay_images(query='brick texture', per_page=200, total_images=450)

print("Images downloaded successfully!")
